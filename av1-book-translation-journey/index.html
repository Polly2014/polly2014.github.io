<!doctype html><html><head><title>Polly Blog - AI Assistant, Tutorials, and Insights</title><meta content="Explore Polly Blog for AI tutorials, insights, and updates on cutting-edge technology." name=description><meta content="Polly, Blog, AI Blog, AI Assistant, Tutorials, Technology Blog, Baoli Wang" name=keywords><meta content="width=device-width,initial-scale=1" name=viewport><meta content="text/html; charset=utf-8" http-equiv=content-type><link rel="shortcut icon" href=https://polly.wang/images/polly.ico type=image/x-icon><link href=https://polly.wang/images/polly.ico rel=icon type=image/x-icon><link href=https://polly.wang/images/polly.ico rel=apple-touch-icon><link href=https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/pure-min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/grids-responsive-min.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css rel=stylesheet><link href=https://polly.wang/css/style_new.css rel=stylesheet><script src="https://www.googletagmanager.com/gtag/js?id=G-8JD13N7PHS" async></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date());gtag('config','G-8JD13N7PHS')</script><body><div class=menu-toggle><img alt=Menu src=https://polly.wang/images/polly.png></div><div class=overlay></div><div class="pure-g container"><div class="sidebar pure-u-1 pure-u-md-1-5"><div class=title><a class=pure-menu-heading href=https://polly.wang> <img class="avatar pure-img-responsive" src=https://polly.wang/images/polly.png> </a><div class=introduction><p>Polly's Blog</div><div class=nav><ul class=nav-links><li><a href=https://polly.wang><i class="fas fa-home"></i>Home</a><li><a href=https://polly.wang/archive><i class="fas fa-archive"></i>Archive</a><li><a href=https://polly.wang/category><i class="fas fa-folder"></i>Category</a><li><a href=https://polly.wang/blog><i class="fas fa-file-alt"></i>Posts</a><li><a href=https://polly.wang/publication><i class="fas fa-file-pdf"></i>Research</a><li><a href=https://polly.wang/changelog><i class="fas fa-history"></i>Change log</a><li><a href=https://polly.wang/about><i class="fas fa-info-circle"></i>About Me</a></ul></div><div class=social><ul class=social-links><li><a href=mailto:26716201@qq.com><i class="fas fa-envelope"></i></a><li><a href=https://twitter.com/Polly__007><i class="fab fa-twitter"></i></a><li><a href=https://www.linkedin.com/in/baoliwang><i class="fab fa-linkedin-in"></i></a><li><a href=https://github.com/Polly2014><i class="fab fa-github"></i></a></ul></div></div></div><div class="content pure-u-1 pure-u-md-4-5"><div class=blog-post><h1>凌晨一点到六点：用AI翻译一本320页的AV1视频编解码技术书籍</h1><div class=content><h2 id=kai-pian-yi-ci-yi-wai-de-ji-yang>开篇：一次意外的"技痒"</h2><p>12月26日，本来是我休假的日子。<p>下午开着大鼠标去公司充电，顺便和同事闲聊。聊着聊着，话题转到了我最近在Hackathon上开发的Master-Translator项目——一个专门用于长文档翻译的MCP Server。<p>"我老公那边有本书需要翻译，"同事突然说，"他是书的作者之一，出版社一直催着要英文版，但考虑到成本和复杂度，迟迟没动。"<p>我眼睛一亮："什么书？"<p>"《AV1视频编解码标准：原理与算法实现》，320多页，全是技术内容，公式、表格、架构图一大堆。"<p>巧了。我刚刚重构升级了Master-Translator，正愁没有硬核场景测试。这不就是最好的试金石吗？<p>"发我看看？"<p>当天晚上，我拿到了PDF。凌晨一点，大多数人已经进入梦乡，而我盯着屏幕上这本320页的技术书籍，<strong>技痒难耐</strong>。<p>一个疯狂的想法冒了出来：<strong>能不能用Master-Translator，在一个通宵内完成整本书的中译英？</strong><p>答案是：可以。但过程远比想象中曲折精彩。<h2 id=part-1-zhan-qian-zhun-bei-pdfjie-xi-de-jian-nan-jue-ze>Part 1: 战前准备 - PDF解析的艰难抉择</h2><h3 id=cong-pdfdao-markdown>从PDF到Markdown</h3><p>拿到手的是一个PDF文件。第一个问题就来了：<strong>如何高质量地将PDF转换为可编辑的Markdown？</strong><p>我测试了多种方案，最终选择了 <strong>MinerU</strong>——一个开源的高质量PDF解析工具。<h3 id=wei-shi-yao-xuan-ze-mineru>为什么选择 MinerU？</h3><table><thead><tr><th>工具<th>优点<th>缺点<tbody><tr><td><strong>Marker</strong><td>开源免费，公式识别好<td>表格处理一般<tr><td><strong>Mathpix</strong><td>公式识别极佳<td>收费，有配额限制<tr><td><strong>Doc2X</strong><td>综合效果好<td>需要API Key<tr><td><strong>MinerU</strong> ✅<td>开源、表格/公式/图片都很好<td>需要本地部署</table><p>MinerU 是由 OpenDataLab 开源的 PDF 解析工具，对技术文档的支持非常好——公式、表格、图片都能高质量提取。解析后的Markdown文件巨大——<strong>812KB，8122行</strong>，包含：<ul><li>📖 11个完整章节<li>🖼️ 240张技术图片<li>📊 85个HTML表格（带单元格合并）<li>🔢 数百个LaTeX数学公式<li>📚 48条参考文献</ul><p>这不是一个普通的文档翻译任务，这是一场<strong>技术马拉松</strong>。<h3 id=wei-shi-yao-bu-neng-yong-googlefan-yi-deepl-chatgpt>为什么不能用Google翻译 / DeepL / ChatGPT？</h3><p>在动手之前，我也考虑过现成的工具。但很快意识到它们无法胜任：<table><thead><tr><th>工具<th>核心问题<tbody><tr><td><strong>Google Translate</strong><td>PDF翻译会破坏所有格式——85张表格会变成乱码，240张图片位置丢失<tr><td><strong>DeepL</strong><td>30MB文件限制，更致命的是无法维护术语一致性（"帧内预测"在不同段落可能翻译不同）<tr><td><strong>ChatGPT</strong><td>长文档的"道德风险"——它会自作主张地总结而非忠实翻译，44万字需要150+次对话</table><p>这些工具都是为短文本设计的。面对320页的技术书籍，它们要么格式崩溃，要么上下文断裂，要么术语漂移。<p>这正是我开发 Master-Translator 的初衷：<strong>为长文档翻译而生</strong>。<h2 id=part-2-ling-chen-de-fan-yi-zhi-lu>Part 2: 凌晨的翻译之旅</h2><h3 id=master-translator-mcp-serverdeng-chang>Master-Translator-MCP-Server登场</h3><p>凌晨1点30分，我启动了自研的<code>Master-Translator-MCP-Server</code>。这是一个专门为长文档翻译设计的MCP工具集，核心特性包括：<ul><li><strong>智能分块</strong>：基于章节边界的语义分割<li><strong>术语一致性</strong>：跨块术语表维护<li><strong>上下文编织</strong>：块间上下文传递<li><strong>增量翻译</strong>：支持断点续传</ul><pre class=language-bash data-lang=bash style=background:#2b303b;color:#c0c5ce><code class=language-bash data-lang=bash><span style=color:#65737e># 启动翻译任务
</span><span style=color:#bf616a>mcp_master-transl_translate_document</span><span>(
</span><span>    </span><span style=color:#bf616a>document_path</span><span>="</span><span style=color:#a3be8c>/path/to/full_chinese.md</span><span>"</span><span style=color:#a3be8c>,
</span><span>    </span><span style=color:#bf616a>target_language</span><span>="</span><span style=color:#a3be8c>english</span><span>"</span><span style=color:#a3be8c>,
</span><span>    </span><span style=color:#bf616a>model</span><span>="</span><span style=color:#a3be8c>deepseek-v3</span><span>"
</span><span>)
</span></code></pre><h3 id=ling-chen-3dian-di-yi-ci-wei-ji>凌晨3点：第一次危机</h3><p>翻译进行到约60%时，我发现了一个问题——<strong>Token消耗超出预期</strong>。<p>320页的技术书籍，包含大量专业术语和公式，每个分块都需要：<ul><li>输入：原文 + 上下文 + 术语表<li>输出：完整翻译</ul><p>我快速切换到了更经济的模型配置，继续战斗。<h3 id=ling-chen-5dian-shu-guang-chu-xian>凌晨5点：曙光初现</h3><p>翻译主体完成。但还不能睡——我需要做<strong>质量验证</strong>。<p>快速扫描发现几个问题：<ol><li>一些图片引用路径有typo<li>部分公式的LaTeX格式需要调整<li>整体结构需要复核</ol><p>记录下这些问题后，我终于在6点多躺下，眯了一会儿。<h2 id=part-3-qi-chuang-hou-de-liang-xi-yu-tiao-zhan>Part 3: 起床后的惊喜与挑战</h2><h3 id=tu-pian-yin-yong-chai-yi-pai-cha>图片引用差异排查</h3><p>起床后的第一件事，是检查翻译质量。我写了一个脚本来统计中英文版本的差异：<pre class=language-bash data-lang=bash style=background:#2b303b;color:#c0c5ce><code class=language-bash data-lang=bash><span style=color:#65737e># 中文版图片引用
</span><span style=color:#bf616a>grep -o </span><span>'</span><span style=color:#a3be8c>!\[.*\](images/[^)]*\.png)</span><span>' full_chinese.md | </span><span style=color:#bf616a>wc -l
</span><span style=color:#65737e># 结果: 240
</span><span>
</span><span style=color:#65737e># 英文版图片引用  
</span><span style=color:#bf616a>grep -o </span><span>'</span><span style=color:#a3be8c>!\[.*\](images/[^)]*\.png)</span><span>' full_english.md | </span><span style=color:#bf616a>wc -l
</span><span style=color:#65737e># 结果: 238
</span></code></pre><p><strong>少了2张图片！</strong><h3 id=shi-zong-de-di-10-2jie>失踪的第10.2节</h3><p>经过仔细排查，我发现了问题所在——<strong>整个10.2节（电影颗粒模型估计）在翻译过程中丢失了</strong>！<p>这一节包含：<ul><li>约180行内容<li>17,897个字符<li>3个子章节（10.2.1、10.2.2、10.2.3）<li>2张关键图片</ul><p>原因分析：这一节恰好位于分块边界处，在某次处理中被遗漏。<h3 id=bu-yi-xiu-fu>补译修复</h3><p>发现问题后，我立即使用Claude完成了这一节的补译：<pre class=language-markdown data-lang=markdown style=background:#2b303b;color:#c0c5ce><code class=language-markdown data-lang=markdown><span style=color:#8fa1b3># 10.2 Film Grain Model Estimation
</span><span>
</span><span>The film grain algorithm in AV1 codec includes two parts: 
</span><span>the encoder-side film grain model estimation and the 
</span><span>decoder-side film grain synthesis...
</span><span>
</span><span style=color:#8fa1b3>## 10.2.1 Image Content Analysis
</span><span>...
</span><span>
</span><span style=color:#8fa1b3>## 10.2.2 Image Denoising  
</span><span>...
</span><span>
</span><span style=color:#8fa1b3>## 10.2.3 Piecewise Linear Function Estimation
</span><span>...
</span></code></pre><p>修复后再次验证：<strong>240/240 图片引用完全匹配</strong> ✅<h2 id=part-4-worddao-chu-de-yi-wai-tiao-zhan>Part 4: Word导出的意外挑战</h2><p>翻译完成了，但故事还没结束。我需要将Markdown导出为Word文档，供进一步编辑和排版。<h3 id=di-yi-ci-chang-shi-typoradao-chu>第一次尝试：Typora导出</h3><p>用Typora打开Markdown，直接导出Word——<strong>失败</strong>。<p>LaTeX公式解析错误，部分公式因为源PDF的OCR问题存在格式缺陷。<h3 id=di-er-ci-chang-shi-mcpdao-chu-gong-ju>第二次尝试：MCP导出工具</h3><p>使用<code>mcp_master-transl_export_to_word</code>——<strong>部分成功</strong>。<p>生成了267KB的文档，但只有纯文本，图片、表格、公式全部丢失。原来这个工具使用的是基础的<code>python-docx</code>，不支持富格式。<h3 id=di-san-ci-chang-shi-pandoczhi-jie-zhuan-huan>第三次尝试：Pandoc直接转换</h3><pre class=language-bash data-lang=bash style=background:#2b303b;color:#c0c5ce><code class=language-bash data-lang=bash><span style=color:#bf616a>pandoc</span><span> full_english.md</span><span style=color:#bf616a> -o</span><span> full_english.docx</span><span style=color:#bf616a> --embed-resources --standalone
</span></code></pre><p><strong>结果</strong>：图片和公式正常，但85个HTML表格全部变成纯文本！<p>问题根源：源文件中的HTML表格是<strong>单行压缩格式</strong>，并且使用了<code>colspan</code>合并单元格，Pandoc无法正确解析。<h3 id=zui-zhong-fang-an-markdown-html-word>最终方案：Markdown → HTML → Word</h3><p>经过反复尝试，我找到了完美的解决方案：<pre class=language-bash data-lang=bash style=background:#2b303b;color:#c0c5ce><code class=language-bash data-lang=bash><span style=color:#65737e># 步骤1: Markdown → HTML（嵌入所有资源）
</span><span style=color:#bf616a>pandoc</span><span> full_english.md</span><span style=color:#bf616a> -o</span><span> full_english.html \
</span><span style=color:#bf616a>    --embed-resources --standalone --mathjax
</span><span>
</span><span style=color:#65737e># 步骤2: HTML → Word
</span><span style=color:#bf616a>pandoc</span><span> full_english.html</span><span style=color:#bf616a> -o</span><span> full_english_from_html.docx
</span></code></pre><p><strong>成功！</strong> 最终生成了8.1MB的完整Word文档：<ul><li>✅ 240张图片完整嵌入<li>✅ 85个表格正确渲染（包括合并单元格）<li>✅ 数学公式通过MathJax完美呈现</ul><h2 id=part-5-zui-zhong-cheng-guo>Part 5: 最终成果</h2><h3 id=fan-yi-tong-ji>翻译统计</h3><table><thead><tr><th>指标<th>数值<tbody><tr><td>原书页数<td>320页<tr><td>中文原文<td><strong>44万字符</strong><tr><td>英文译文<td><strong>13.5万词</strong> / 93万字节<tr><td>Markdown行数<td>8,122行<tr><td>章节数<td>11章<tr><td>图片数<td>240张<tr><td>表格数<td>85个<tr><td>公式数<td>数百个<tr><td>参考文献<td>48条</table><h3 id=shi-jian-xian>时间线</h3><table><thead><tr><th>时间<th>工作内容<tbody><tr><td>凌晨 1:00<td>开始PDF解析和预处理<tr><td>凌晨 1:30<td>启动Master-Translator翻译<tr><td>凌晨 3:00<td>处理Token消耗问题<tr><td>凌晨 5:00<td>翻译主体完成，初步验证<tr><td>凌晨 6:00+<td>记录问题，小睡休息<tr><td>上午<td>起床，排查图片差异<tr><td>上午<td>发现并补译10.2节<tr><td>下午<td>解决Word导出问题<tr><td>下午 1:10<td><strong>项目完成</strong> 🎉</table><h2 id=ji-zhu-fan-si>技术反思</h2><h3 id=zhe-ci-jing-li-jiao-hui-wo-shi-yao>这次经历教会我什么？</h3><p><strong>1. 边界处理的重要性</strong><p>长文档分块翻译时，块边界处最容易出问题。10.2节的丢失就是一个典型案例。未来需要加强边界检测和完整性验证。<p><strong>2. 格式转换的复杂性</strong><p>Markdown → Word 看似简单，实际上涉及：<ul><li>HTML表格解析<li>LaTeX公式渲染<li>图片嵌入<li>合并单元格处理</ul><p>最终的"两跳转换"方案（MD→HTML→DOCX）是一个有价值的经验。<p><strong>3. AI工具的边界</strong><p>即使是最强大的AI翻译工具，也需要人工复核。这次发现的问题——丢失章节、图片引用错误、公式格式问题——都是AI难以自我发现的。<h3 id=master-translatorde-xia-yi-bu>Master-Translator的下一步</h3><p>基于这次实战，我计划为Master-Translator添加以下功能：<ul><li><input disabled type=checkbox> <strong>完整性校验</strong>：自动比对源文档和译文的结构<li><input disabled type=checkbox> <strong>图片引用审计</strong>：自动检测缺失或错误的图片引用<li><input disabled type=checkbox> <strong>增强型Word导出</strong>：内置两跳转换方案<li><input disabled type=checkbox> <strong>边界重叠检测</strong>：在分块时自动检测并处理边界内容</ul><h2 id=cai-dan-lai-zi-zuo-zhe-de-fan-kui>彩蛋：来自作者的反馈</h2><p>下午，我把翻译样稿（前言 + 第一章 + 第三章）发给了同事。<p>几分钟后，微信消息开始刷屏：<blockquote><p><strong>同事</strong>："这么快[惊讶][惊讶][惊讶]"<p><strong>同事</strong>："辛苦了 辛苦了"<p><strong>同事</strong>："太牛了[强][强][强][强]"<p><strong>同事</strong>："果然技术大佬"<p><strong>同事</strong>："我老公说效果很赞[强][强][强][强]"</blockquote><p>那一刻，通宵的疲惫一扫而空。<p><strong>"效果很赞"</strong>——这四个字，来自书的作者本人，是对这次翻译最好的认可。<p>也许，这不只是一次技术验证，而是一个新故事的开始。<h2 id=jie-yu-shen-ye-de-mo-li>结语：深夜的魔力</h2><p>回顾这个通宵，从凌晨一点的疯狂想法，到下午一点的最终完成——12个小时，320页，44万中文字符翻译为13.5万英文词。<p>这不仅仅是一次翻译任务，更是一次<strong>AI能力边界的探索</strong>。<p>在AI时代，我们能做的事情边界在不断扩展。一个人，一个通宵，一套自研工具，就能完成以前需要专业团队数周才能完成的工作。<p>但同时，这也提醒我：<strong>AI是放大器，不是替代者</strong>。真正的价值在于：<ul><li>理解问题的能力<li>设计解决方案的能力<li>发现和修复问题的能力<li>持续优化工具的能力</ul><p>凌晨的咖啡已经凉了，但完成一件Cool事的满足感，比任何咖啡因都提神。<hr><p><em>本文使用的工具：</em><ul><li><em><a href=https://github.com/opendatalab/MinerU>MinerU</a> - 高质量PDF解析工具</em><li><em><a href=https://github.com/Polly2014/Master-Translator-MCP-Server>Master-Translator-MCP-Server</a> - 长文档翻译MCP工具</em><li><em><a href=https://pandoc.org/>Pandoc</a> - 文档格式转换</em><li><em><a href=https://claude.ai/>Claude</a> - AI编程助手</em></ul><p><em>如果你对AI翻译或MCP开发感兴趣，欢迎在评论区交流！</em></div><div class=navigation></div></div><div id=giscus-container><h2>留言与讨论</h2><div class=giscus></div></div><script data-category="Blog Comments" async crossorigin data-category-id=DIC_kwDOL45duM4CnjlZ data-emit-metadata=0 data-input-position=bottom data-lang=en data-mapping=pathname data-reactions-enabled=1 data-repo=Polly2014/polly2014.github.io data-repo-id=R_kgDOL45duA data-strict=0 data-theme=noborder_light src=https://giscus.app/client.js></script><script type=module>
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        
        mermaid.initialize({
            startOnLoad: false,
            theme: 'base',
            themeVariables: {
                // 灰白黑色调 + 蓝色点缀
                primaryColor: '#e8e8e8',
                primaryTextColor: '#333',
                primaryBorderColor: '#999',
                lineColor: 'rgb(61, 146, 201)',
                secondaryColor: '#f5f5f5',
                tertiaryColor: '#fafafa',
                background: '#f2f2f2',
                mainBkg: '#f5f5f5',
                nodeBorder: '#999',
                clusterBkg: '#eee',
                clusterBorder: '#ccc',
                titleColor: '#333',
                edgeLabelBackground: '#f2f2f2',
                // 文本颜色
                textColor: '#333',
                nodeTextColor: '#333',
                // 其他
                fontFamily: "'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace"
            },
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true,
                curve: 'basis'
            }
        });

        // 查找所有 mermaid 代码块并渲染
        document.querySelectorAll('pre code.language-mermaid').forEach((block, index) => {
            const container = document.createElement('div');
            container.className = 'mermaid';
            container.textContent = block.textContent;
            block.parentNode.replaceWith(container);
        });

        // 渲染所有 mermaid 图表
        await mermaid.run();
    </script><style>.mermaid{background:#fafafa;border:1px solid #ddd;padding:20px;margin:20px 0;overflow-x:auto}.mermaid svg{max-width:100%;height:auto}</style></div></div><script>document.addEventListener('DOMContentLoaded',function(){const c=document.querySelector('.menu-toggle');const d=document.querySelector('.sidebar');const e=document.querySelector('.overlay');function a(){d.classList.toggle('active');e.classList.toggle('active')}c.addEventListener('click',a);e.addEventListener('click',a);let f=0;let g=0;document.addEventListener('touchstart',h=>{f=h.changedTouches[0].screenX},false);document.addEventListener('touchend',h=>{g=h.changedTouches[0].screenX;b()},false);function b(){const h=g- f;if(h>50&&f<30){d.classList.add('active');e.classList.add('active')}else if(h<-50&&d.classList.contains('active')){d.classList.remove('active');e.classList.remove('active')}}})</script>