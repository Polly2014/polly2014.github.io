<!doctype html><html><head><title>Polly Blog - AI Assistant, Tutorials, and Insights</title><meta content="Explore Polly Blog for AI tutorials, insights, and updates on cutting-edge technology." name=description><meta content="Polly, Blog, AI Blog, AI Assistant, Tutorials, Technology Blog, Baoli Wang" name=keywords><meta content="width=device-width,initial-scale=1" name=viewport><meta content="text/html; charset=utf-8" http-equiv=content-type><link rel="shortcut icon" href=https://polly.wang/images/polly.ico type=image/x-icon><link href=https://polly.wang/images/polly.ico rel=icon type=image/x-icon><link href=https://polly.wang/images/polly.ico rel=apple-touch-icon><link href=https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/pure-min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/grids-responsive-min.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css rel=stylesheet><link href=https://polly.wang/css/style_new.css rel=stylesheet><script src="https://www.googletagmanager.com/gtag/js?id=G-8JD13N7PHS" async></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date());gtag('config','G-8JD13N7PHS')</script><body><div class=menu-toggle><img alt=Menu src=https://polly.wang/images/polly.png></div><div class=overlay></div><div class="pure-g container"><div class="sidebar pure-u-1 pure-u-md-1-5"><div class=title><a class=pure-menu-heading href=https://polly.wang> <img class="avatar pure-img-responsive" src=https://polly.wang/images/polly.png> </a><div class=introduction><p>Polly's Blog</div><div class=nav><ul class=nav-links><li><a href=https://polly.wang><i class="fas fa-home"></i>Home</a><li><a href=https://polly.wang/archive><i class="fas fa-archive"></i>Archive</a><li><a href=https://polly.wang/category><i class="fas fa-folder"></i>Category</a><li><a href=https://polly.wang/blog><i class="fas fa-file-alt"></i>Posts</a><li><a href=https://polly.wang/publication><i class="fas fa-file-pdf"></i>Research</a><li><a href=https://polly.wang/changelog><i class="fas fa-history"></i>Change log</a><li><a href=https://polly.wang/about><i class="fas fa-info-circle"></i>About Me</a></ul></div><div class=social><ul class=social-links><li><a href=mailto:26716201@qq.com><i class="fas fa-envelope"></i></a><li><a href=https://twitter.com/Polly__007><i class="fab fa-twitter"></i></a><li><a href=https://www.linkedin.com/in/baoliwang><i class="fab fa-linkedin-in"></i></a><li><a href=https://github.com/Polly2014><i class="fab fa-github"></i></a></ul></div></div></div><div class="content pure-u-1 pure-u-md-4-5"><div class=blog-post><h1>Claude 3.7 Sonnet模型使用成本分析：基于OpenHands实际案例</h1><div class=content><h2 id=yi-yin-yan>一、引言</h2><p>随着大语言模型(LLM)在生产环境中的广泛应用，其使用成本已成为企业关注的焦点。本文通过分析OpenHands平台的实际使用日志，深入解析Claude 3.7 Sonnet模型的收费模式和成本结构，并提出相应的优化策略。<h2 id=er-claude-3-7-sonnetmo-xing-gai-lan>二、Claude 3.7 Sonnet模型概览</h2><p>从日志中可以看出，Claude 3.7 Sonnet模型具有以下关键参数：<pre style=background:#2b303b;color:#c0c5ce><code><span>"key": "claude-3-7-sonnet-20250219",
</span><span>"max_tokens": 128000,
</span><span>"max_input_tokens": 200000,
</span><span>"max_output_tokens": 128000,
</span><span>"input_cost_per_token": 3e-06,  // 每输入token $0.000003
</span><span>"cache_creation_input_token_cost": 3.75e-06,  // 缓存创建的成本为每token $0.00000375
</span><span>"cache_read_input_token_cost": 3e-07,  // 缓存读取的成本为每token $0.0000003
</span><span>"output_cost_per_token": 1.5e-05,  // 每输出token $0.000015
</span></code></pre><p>这些参数揭示了Claude 3.7 Sonnet的基础定价结构，输入token比输出token便宜5倍，并且模型支持高达20万输入token的超长上下文。此外，模型还支持以下功能：<ul><li><strong>视觉能力</strong>: 支持图像输入和处理<li><strong>工具调用</strong>: 支持函数调用和工具选择<li><strong>PDF输入</strong>: 原生支持PDF文档处理<li><strong>提示缓存</strong>: 支持提示缓存以优化性能和成本<li><strong>响应格式控制</strong>: 支持结构化输出格式控制</ul><h2 id=san-shi-ji-ren-wu-zhong-de-cheng-ben-gou-cheng>三、实际任务中的成本构成</h2><p>我们以一个杭州三天旅游规划任务为例，分析整个过程中的成本构成。此任务需要生成一个基于Flask的旅游规划网页。<h3 id=hui-hua-jiao-hu-cheng-ben-wan-zheng-fen-xi-biao>会话交互成本完整分析表</h3><table><thead><tr><th>调用序号<th>输入令牌<th>输出令牌<th>缓存命中<th>缓存写入<th>成本(USD)<th>累计成本(USD)<th>响应时间(秒)<tbody><tr><td>1<td>5,411<td>4,202<td>0<td>5,407<td>0.10<td>0.10<td>58.89<tr><td>2<td>9,639<td>102<td>5,407<td>4,226<td>0.03<td>0.13<td>3.06<tr><td>3<td>10,457<td>99<td>9,633<td>818<td>0.01<td>0.14<td>2.35<tr><td>4<td>10,753<td>419<td>10,451<td>296<td>0.01<td>0.15<td>8.07</table><h3 id=1-chu-ci-qing-qiu-yu-gui-hua-jie-duan>1. 初次请求与规划阶段</h3><pre style=background:#2b303b;color:#c0c5ce><code><span>12:09:37 - openhands:DEBUG: llm.py:561 - Cost: 0.10 USD | Accumulated Cost: 0.10 USD
</span><span>Response Latency: 58.893 seconds
</span><span>Input tokens: 5411 | Output tokens: 4202
</span><span>Input tokens (cache write): 5407
</span></code></pre><p>第一次调用是成本最高的，分析如下：<ul><li>输入成本：5411 tokens × $0.000003 = $0.0162<li>输出成本：4202 tokens × $0.000015 = $0.0630<li>缓存写入成本：5407 tokens × $0.00000375 - 5411 tokens × $0.000003 = $0.0001<li>总成本：约$0.10</ul><h3 id=2-wen-jian-chuang-jian-hou-de-zhi-ling-gui-hua>2. 文件创建后的指令规划</h3><pre style=background:#2b303b;color:#c0c5ce><code><span>12:09:40 - openhands:DEBUG: llm.py:561 - Cost: 0.03 USD | Accumulated Cost: 0.13 USD
</span><span>Response Latency: 3.062 seconds
</span><span>Input tokens: 9639 | Output tokens: 102
</span><span>Input tokens (cache hit): 5407
</span><span>Input tokens (cache write): 4226
</span></code></pre><p>第二次调用成本大幅降低：<ul><li>缓存命中节省：5407 tokens (使用缓存，成本为 5407 × $0.0000003 = $0.0016，比正常输入节省了97%)<li>新增输入成本：4232 tokens × $0.000003 = $0.0127<li>输出成本：102 tokens × $0.000015 = $0.0015<li>缓存写入成本：4226 tokens × ($0.00000375 - $0.000003) = $0.0003<li>总成本：约$0.03</ul><h3 id=3-yi-lai-an-zhuang-hou-de-zhi-ling-gui-hua>3. 依赖安装后的指令规划</h3><pre style=background:#2b303b;color:#c0c5ce><code><span>12:09:45 - openhands:DEBUG: llm.py:561 - Cost: 0.01 USD | Accumulated Cost: 0.14 USD
</span><span>Response Latency: 2.354 seconds
</span><span>Input tokens: 10457 | Output tokens: 99
</span><span>Input tokens (cache hit): 9633
</span><span>Input tokens (cache write): 818
</span></code></pre><p>第三次调用成本进一步降低：<ul><li>缓存命中节省：9633 tokens (缓存成本 $0.0029，比正常输入节省了97%)<li>新增输入成本：824 tokens × $0.000003 = $0.0025<li>输出成本：99 tokens × $0.000015 = $0.0015<li>缓存写入成本：818 tokens × ($0.00000375 - $0.000003) = $0.0001<li>总成本：约$0.01</ul><h3 id=4-ying-yong-qi-dong-hou-de-zui-zhong-hui-fu>4. 应用启动后的最终回复</h3><pre style=background:#2b303b;color:#c0c5ce><code><span>12:10:24 - openhands:DEBUG: llm.py:561 - Cost: 0.01 USD | Accumulated Cost: 0.15 USD
</span><span>Response Latency: 8.065 seconds
</span><span>Input tokens: 10753 | Output tokens: 419
</span><span>Input tokens (cache hit): 10451
</span><span>Input tokens (cache write): 296
</span></code></pre><p>最终调用：<ul><li>缓存命中节省：10451 tokens (缓存成本 $0.0031，比正常输入节省了97%)<li>新增输入成本：302 tokens × $0.000003 = $0.0009<li>输出成本：419 tokens × $0.000015 = $0.0063<li>缓存写入成本：296 tokens × ($0.00000375 - $0.000003) = $0.0000<li>总成本：约$0.01</ul><h3 id=5-ren-wu-zong-cheng-ben>5. 任务总成本</h3><p>整个任务的累计成本为$0.15259，共处理了：<ul><li>输入tokens：36,260 tokens (含重复)<li>缓存命中：25,491 tokens (占70.3%)<li>实际计费输入令牌：10,769 (未命中缓存的部分)<li>输出tokens：4,822 tokens<li>实际编码工作：创建了一个完整的Flask网页应用<li><strong>平均每1000个输出令牌成本</strong>: $0.03164</ul><h2 id=si-cheng-ben-xiao-lu-fen-xi>四、成本效率分析</h2><h3 id=1-huan-cun-ji-zhi-de-xian-zhu-xiao-yi>1. 缓存机制的显著效益</h3><p>通过对日志的分析，我们发现缓存机制极大地降低了API调用成本：<table><thead><tr><th>调用序号<th>缓存命中率<th>成本降低比例<th>延迟时间<th>处理速率(tokens/秒)<tbody><tr><td>1<td>0%<td>0%<td>58.89秒<td>163<tr><td>2<td>56.1%<td>75.4%<td>3.06秒<td>3,142<tr><td>3<td>92.1%<td>92.3%<td>2.35秒<td>4,398<tr><td>4<td>97.2%<td>93.9%<td>8.07秒<td>1,380</table><p>随着会话进行，缓存命中率不断提高，第四次API调用的缓存命中率达到了惊人的97.2%，这不仅降低了成本，也显著提高了响应速度。<h3 id=2-ling-ren-zhu-mu-de-cheng-ben-xiao-lu>2. 令人瞩目的成本效率</h3><ul><li>首次调用成本占总成本的67%<li>后续三次调用虽包含大量token，但总共仅占33%的成本<li>平均每个输出token的综合成本为$0.000031（考虑输入成本）<li>对比未使用缓存的情况，节省了约65%的成本<li>平均每次调用成本仅为$0.03814</ul><p>下图展示了每次调用的成本分布：<pre style=background:#2b303b;color:#c0c5ce><code><span>调用成本分布 (总计 $0.15)
</span><span>[█████████████████████████████████████] 67% - 首次调用 ($0.10)
</span><span>[███████████] 20% - 第二次调用 ($0.03)
</span><span>[████] 7% - 第三次调用 ($0.01)
</span><span>[████] 7% - 第四次调用 ($0.01)
</span></code></pre><h3 id=3-mo-xing-yan-chi-yu-tokenguan-xi>3. 模型延迟与token关系</h3><pre style=background:#2b303b;color:#c0c5ce><code><span>处理速率分析：
</span><span>第一次: 58.9秒处理9,613 tokens，处理速率163 tokens/秒
</span><span>第二次: 3.1秒处理9,741 tokens，处理速率3,142 tokens/秒
</span><span>第三次: 2.4秒处理10,556 tokens，处理速率4,398 tokens/秒
</span><span>第四次: 8.1秒处理11,172 tokens，处理速率1,380 tokens/秒
</span></code></pre><p>从上述数据可以看出，缓存命中显著提高了处理速度，但最终回复较长时可能导致延迟增加。值得注意的是，当缓存命中率提高时，处理速率可以提升到初次请求的27倍之多。<h2 id=wu-cheng-ben-you-hua-ce-lue>五、成本优化策略</h2><p>基于对Claude 3.7 Sonnet模型使用成本的分析，我们提出以下优化策略：<h3 id=1-chong-fen-li-yong-huan-cun-ji-zhi>1. 充分利用缓存机制</h3><ul><li>设计对话流程时保持上下文连贯性，增加缓存命中率<li>在系统设计中考虑缓存策略，如本例中的<code>caching_prompt=True</code>配置<li>监控缓存命中指标，识别优化机会<li>构建缓存预热机制，对于常见问题提前构建缓存</ul><h3 id=2-he-li-kong-zhi-shu-chu-tokenshu-liang>2. 合理控制输出token数量</h3><p>由于输出token的成本是输入token的5倍，控制输出长度尤为重要：<ul><li>使用明确的指令限制回复长度<li>对于生成型任务，可以分步骤生成，减少冗余输出<li>在适当场景使用temperature=0，减少不必要的创意输出<li>针对特定场景使用<code>response_format</code>参数限制输出格式</ul><h3 id=3-you-hua-shang-xia-wen-chuang-kou-da-xiao>3. 优化上下文窗口大小</h3><ul><li>定期清理不必要的上下文内容，避免无效信息占用token<li>使用总结代替完整历史，在保留关键信息的同时减少token用量<li>针对不同任务类型选择合适的上下文管理策略<li>实现智能上下文裁剪算法，优先保留重要内容</ul><h3 id=4-mo-xing-xuan-ze-fen-ceng-ce-lue>4. 模型选择分层策略</h3><ul><li>对于简单任务使用更轻量的模型，如Claude 3 Haiku<li>复杂任务才使用Claude 3.7 Sonnet等高级模型<li>建立模型使用成本/效果评估矩阵，指导选型决策<li>实现级联调用架构，由简单模型决定是否需要调用高级模型</ul><h2 id=liu-mo-xing-biao-xian-yu-jie-zhi-ping-gu>六、模型表现与价值评估</h2><p>从日志中可以看出，Claude 3.7 Sonnet在以下方面表现出色：<ol><li><strong>技术理解能力</strong>：正确识别了需要使用Flask框架创建网页应用<li><strong>编程能力</strong>：生成了可直接运行的代码，包括正确的语法和逻辑<li><strong>依赖推理</strong>：自主判断并安装了必要的依赖包<li><strong>问题解决能力</strong>：完成了从简单指令到实际可用应用的转换</ol><p>这些能力在$0.15美元的成本下交付，相比人工开发的时间成本和机会成本，呈现出显著的经济价值。<h3 id=cheng-ben-yu-xiao-yi-dui-bi-fen-xi>成本与效益对比分析</h3><p>如果由人类开发者完成同样的任务：<table><thead><tr><th>资源类型<th>人工开发<th>Claude 3.7 Sonnet<tbody><tr><td>开发时间<td>1-2小时<td>2分钟<tr><td>成本<td>$50-$200<td>$0.15<tr><td>迭代周期<td>长<td>即时<tr><td>可扩展性<td>需要更多人力<td>可无限扩展</table><p>从这个对比可以看出，即使考虑到人工复核和调整的时间，使用Claude 3.7 Sonnet进行开发仍然具有显著的成本优势。<h2 id=qi-jie-lun-yu-zhan-wang>七、结论与展望</h2><p>通过分析Claude 3.7 Sonnet模型在实际应用场景中的成本构成，我们可以得出以下结论：<ol><li>Claude 3.7 Sonnet的定价结构设计合理，通过缓存机制能够有效降低成本<li>连续多轮对话具有明显的成本效率，初次调用后成本显著下降<li>通过策略优化，可以在保持或提高模型效用的同时，大幅降低使用成本<li>模型性能表现良好：除首次调用外，其他响应时间均较短，用户体验良好</ol><h3 id=wei-lai-qu-shi-yu-ce>未来趋势预测</h3><p>随着大语言模型技术的不断发展，我们预计将看到以下趋势：<ol><li><strong>定价结构更加精细化</strong>：根据不同类型的操作和任务调整价格<li><strong>缓存技术进一步增强</strong>：更智能的缓存策略将进一步降低运行成本<li><strong>多层级模型架构普及</strong>：根据任务复杂度自动选择适当的模型层级<li><strong>本地与云混合部署</strong>：结合本地运行和云服务的优势，进一步优化成本结构</ol><p>如果您正在使用Claude等大模型进行业务开发，希望本文的数据分析和优化建议能为您提供参考。欢迎在评论区分享您的使用经验和成本优化策略！</div><div class=navigation></div></div><div id=giscus-container><h2>留言与讨论</h2><div class=giscus></div></div><script data-category="Blog Comments" async crossorigin data-category-id=DIC_kwDOL45duM4CnjlZ data-emit-metadata=0 data-input-position=bottom data-lang=en data-mapping=pathname data-reactions-enabled=1 data-repo=Polly2014/polly2014.github.io data-repo-id=R_kgDOL45duA data-strict=0 data-theme=noborder_light src=https://giscus.app/client.js></script></div></div><script>document.addEventListener('DOMContentLoaded',function(){const c=document.querySelector('.menu-toggle');const d=document.querySelector('.sidebar');const e=document.querySelector('.overlay');function a(){d.classList.toggle('active');e.classList.toggle('active')}c.addEventListener('click',a);e.addEventListener('click',a);let f=0;let g=0;document.addEventListener('touchstart',h=>{f=h.changedTouches[0].screenX},false);document.addEventListener('touchend',h=>{g=h.changedTouches[0].screenX;b()},false);function b(){const h=g- f;if(h>50&&f<30){d.classList.add('active');e.classList.add('active')}else if(h<-50&&d.classList.contains('active')){d.classList.remove('active');e.classList.remove('active')}}})</script>