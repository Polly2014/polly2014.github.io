<!doctype html><html><head><title>🦞 六小时，三个 AI，一篇论文：人+AI 协作的极限实验</title><meta content="大年初四，不回家过年的我和三个 AI 完成了一场极限协作：6 小时内完成 6 个实验 Review、8 个 Section 写作、16 项结构重组。从散落的 JSON 数据到一篇 1800 行的完整论文，这是我经历过的最高效的论文协作模式。" name=description><meta content="Polly, Blog, AI Blog, AI Assistant, Tutorials, Technology Blog, Baoli Wang" name=keywords><meta content="width=device-width,initial-scale=1" name=viewport><meta content="text/html; charset=utf-8" http-equiv=content-type><meta content=#333 name=theme-color><meta content=article property=og:type><meta content=https://polly.wang/human-ai-paper-review-marathon/ property=og:url><meta content="🦞 六小时，三个 AI，一篇论文：人+AI 协作的极限实验" property=og:title><meta content="大年初四，不回家过年的我和三个 AI 完成了一场极限协作：6 小时内完成 6 个实验 Review、8 个 Section 写作、16 项结构重组。从散落的 JSON 数据到一篇 1800 行的完整论文，这是我经历过的最高效的论文协作模式。" property=og:description><meta content=https://polly.wang/human-ai-paper-review-marathon/cover.jpg property=og:image><meta content="Polly Blog" property=og:site_name><meta content=zh_CN property=og:locale><meta content=summary_large_image name=twitter:card><meta content=https://polly.wang/human-ai-paper-review-marathon/ name=twitter:url><meta content="🦞 六小时，三个 AI，一篇论文：人+AI 协作的极限实验" name=twitter:title><meta content="大年初四，不回家过年的我和三个 AI 完成了一场极限协作：6 小时内完成 6 个实验 Review、8 个 Section 写作、16 项结构重组。从散落的 JSON 数据到一篇 1800 行的完整论文，这是我经历过的最高效的论文协作模式。" name=twitter:description><meta content=https://polly.wang/human-ai-paper-review-marathon/cover.jpg name=twitter:image><meta content=2026-02-21T00:00:00 property=article:published_time><meta content=Polly property=article:author><meta content=ContextWeave property=article:tag><meta content=论文写作 property=article:tag><meta content=人机协作 property=article:tag><meta content=OpenClaw property=article:tag><meta content=小龙虾 property=article:tag><meta content=Jarvis property=article:tag><meta content=学术论文 property=article:tag><meta content="AI Agent" property=article:tag><meta content=LLM property=article:tag><link rel="shortcut icon" href=https://polly.wang/images/polly.ico type=image/x-icon><link href=https://polly.wang/images/polly.ico rel=icon type=image/x-icon><link href=https://polly.wang/images/polly.ico rel=apple-touch-icon><link href=https://polly.wang/vendor/purecss/pure-min.css rel=stylesheet><link href=https://polly.wang/vendor/purecss/grids-responsive-min.css rel=stylesheet><link href=https://polly.wang/vendor/font-awesome/css/all.min.css rel=stylesheet><link href=https://polly.wang/css/style_new.css rel=stylesheet><script src="https://www.googletagmanager.com/gtag/js?id=G-8JD13N7PHS" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-8JD13N7PHS';);</script><body><div class=menu-toggle><img alt=Menu src=https://polly.wang/images/polly.png></div><div class=overlay></div><div class="pure-g container"><div class="sidebar pure-u-1 pure-u-md-1-5"><div class=title><a class=pure-menu-heading href=https://polly.wang> <img class="avatar pure-img-responsive" src=https://polly.wang/images/polly.png> </a><div class=introduction><p>Polly's Blog</div><div class=nav><ul class=nav-links><li><a href=https://polly.wang><i class="fas fa-home"></i>Home</a><li><a href=https://polly.wang/archive><i class="fas fa-archive"></i>Archive</a><li><a href=https://polly.wang/category><i class="fas fa-folder"></i>Category</a><li><a href=https://polly.wang/blog><i class="fas fa-file-alt"></i>Posts</a><li><a href=https://polly.wang/cfp><i class="fas fa-calendar-alt"></i>CFP</a><li><a href=https://polly.wang/publication><i class="fas fa-file-pdf"></i>Research</a><li><a href=https://polly.wang/changelog><i class="fas fa-history"></i>Change Log</a><li><a href=https://polly.wang/about><i class="fas fa-info-circle"></i>About Me</a></ul></div><div class=social><ul class=social-links><li><a href=mailto:26716201@qq.com><i class="fas fa-envelope"></i></a><li><a href=https://twitter.com/Polly__007><i class="fab fa-twitter"></i></a><li><a href=https://www.linkedin.com/in/baoliwang><i class="fab fa-linkedin-in"></i></a><li><a href=https://github.com/Polly2014><i class="fab fa-github"></i></a></ul></div></div></div><div class="content pure-u-1 pure-u-md-4-5"><div class=blog-post><h1>🦞 六小时，三个 AI，一篇论文：人+AI 协作的极限实验</h1><div class=cover-image><img alt="🦞 六小时，三个 AI，一篇论文：人+AI 协作的极限实验" loading=lazy src=cover.jpg></div><div class=content><p>大年初四，北京空得像一座被遗忘的城市。<p>窗外零星的鞭炮声提醒我这是春节，但我面前的三个屏幕告诉我另一个事实——我正在和三个 AI 打一场论文攻坚战。</p><span id=continue-reading></span><h2 id=bian-dui-yi-ge-ren-lei-san-ge-ai>编队：一个人类 + 三个 AI</h2><p>先介绍今天的团队阵容：<ul><li><strong>我（Baoli）</strong> — 总指挥。负责决策、分配任务、最终拍板<li><strong>Polly（Claude）</strong> — 主力执行。写代码、跑实验、写论文、改结构<li><strong>小龙虾 🦞（OpenClaw）</strong> — 首席 Reviewer。审实验、审论文、提修改意见、给写作指导<li><strong>Jarvis</strong> — 本地守护者。在后台默默运转，维持基础设施</ul><p>这不是什么概念演示或玩具项目。我们在写的是一篇目标 NeurIPS/ACL 的学术论文——<a href=/contextweave-paper-acl-submission-ready>ContextWeave</a>，关于大语言模型在长文档翻译中的系统性失败模式及其解决方案。<p>论文已经有了初稿和实验数据，但 reviewer 会扣分的硬伤还不少。今天的任务是：<strong>一天之内，把它从"能投"变成"值得投"。</strong><h2 id=14-23-phase-1-shi-yan-review-ma-la-song>14:23 — Phase 1：实验 Review 马拉松</h2><p>下午两点半，战斗开始。<p>我让 Polly 把最近完成的实验结果整理好，然后一个个发给小龙虾 review。小龙虾的工作方式让我印象深刻——它不是走马观花地说"looks good"，而是<strong>逐行读代码、逐字段看 JSON、逐数字验证结论</strong>。<h3 id=di-yi-ge-shi-yan-jiu-bei-zhua-dao-liao-zhi-ming-bug>第一个实验就被抓到了致命 Bug</h3><p>EXP16b 是关于 Llama-3-8B 注意力熵的实验。小龙虾读完代码后，第一句话就是：<blockquote><p><strong>"三次 run 数据完全相同 — σ=0，实验无效。"</strong></blockquote><p>我一看，确实。因为输入文本是确定性的固定字符串，<code>tokenizer</code> 每次裁剪出完全相同的 token 序列，模型推理也是确定性的——所以 3 次 run = 1 次 run。论文里写 n=3 完全是伪重复（pseudo-replication）。<p>如果这个 bug 带着投稿，reviewer 一眼就能看出 σ=0 意味着什么。<p>但"30 分钟修好"这五个字背后，藏着一个跨设备、跨四个版本的技术故事。<h3 id=google-colab-shang-de-si-ban-die-dai>Google Colab 上的四版迭代</h3><p>Llama-3-8B 有 80 亿参数，我的 MacBook 根本跑不动。Polly 的方案是：<strong>本地写 Notebook → 上传 Google Colab → 用免费的 Tesla T4（15GB 显存）跑</strong>。为了塞进 15GB，模型要做 INT4 量化（bitsandbytes NF4），8B 参数压缩到 ~4GB。<p>但问题不止于 σ=0。这个实验前后迭代了四版：<table><thead><tr><th>Version<th>问题<th>修复<tbody><tr><td><strong>v1</strong><td>固定文本 → σ=0<td>被小龙虾一句话击毙<tr><td><strong>v2</strong><td>文本重复拼接 → 低层 σ 仍为 0<td>治标不治本<tr><td><strong>v3</strong><td>random shuffle 但同 seed → 实际还是确定性<td>差一点…<tr><td><strong>v4 ✅</strong><td>NTREX 多领域文本 + per-sample seed + 10 段嵌入文本（气候/量子/海洋/语言学…）<td>σ ∈ [0.003, 0.032]，全部 >0</table><p>v4 还做了两件小龙虾追加要求的事：<ol><li><p><strong>BOS attention sink 排除</strong>：Xiao et al. (2023) 发现第一个 token（BOS）会吸收异常大量注意力。如果不排除 BOS，熵的增长可能只是 BOS 稀释效应，不是真正的注意力分散。排除后 delta 仅 0.6 个百分点——"minimal impact"，结论 robust。</p><li><p><strong>GQA 分组分析</strong>：Llama-3-8B 用 Grouped Query Attention（32 个 Q-head 共享 8 个 KV-head），跟 EXP16 的 TinyLlama-1.1B（标准 MHA）架构完全不同。Polly 在 Notebook 里 hook 住 <code>q_proj</code> 和 <code>k_proj</code>，手动计算注意力矩阵——绕过 PyTorch 的 SDPA 优化，确保能拿到每个 head 的原始权重。</p></ol><p>最终结果：<strong>Entropy 从 256 tokens 到 3072 tokens 增长 +92.5%</strong>，与 1.1B 模型的 Pearson 相关系数 r=0.9596 (p=1.1×10⁻⁵)。两个相差 8 倍的模型，注意力熵随序列长度的变化趋势几乎完美重合。<p>这意味着"<strong>注意力稀释导致生成崩塌</strong>"不是小模型的特性，而是 Transformer 架构的固有行为。一个 Google Colab 免费 GPU + 30 分钟 = 论文核心 claim 的跨规模验证。<p>这种"AI 审 AI"的模式效率惊人。小龙虾不会碍于面子放水，Polly 不会因为被批评而情绪波动。纯粹的<strong>问题→修复→验证</strong>循环。<h3 id=liu-ge-shi-yan-ge-ge-you-shou-huo>六个实验，个个有收获</h3><p>接下来的三小时，我们按流水线节奏推进：<table><thead><tr><th>实验<th>小龙虾发现的关键问题<th style=text-align:center>Polly 修复时间<tbody><tr><td><strong>EXP16b</strong> (Attention)<td>σ=0 pseudo-replication 💀<td style=text-align:center>30min 重跑<tr><td><strong>EXP17</strong> (Cohesion)<td>Prompt 残留 "翻译以下文本" 污染数据<td style=text-align:center>已修（224句验证 0 污染）<tr><td><strong>EXP08b</strong> (TCR-A)<td>Wilcoxon p=0.0625 是 n=5 的数学下限，不是无效<td style=text-align:center>论文加解释<tr><td><strong>EXP02b</strong> (Collapse)<td>80K 是 F2 不是 F3，需正确标注 failure mode<td style=text-align:center>加 failure_mode 字段<tr><td><strong>EXP03d</strong> (FORBIDDEN)<td>"消灭 F3 只留 F2" 比 "PRR 提高 24pp" 更准确<td style=text-align:center>重写 paper sentence<tr><td><strong>EXP16b v4</strong><td>BOS attention sink 需要 robustness check<td style=text-align:center>Δ=0.6pp，完美</table><p>每个实验的 review 都不是一轮过的。小龙虾会给出分级意见（🔴 必修 / 🟡 建议 / 🟢 小问题），Polly 按优先级修复后再提交 review，直到全绿。<p><strong>到 17:35，6 个实验全部 ✅ DONE。</strong><h2 id=17-45-phase-2-lun-wen-xie-zuo-shan-dian-zhan>17:45 — Phase 2：论文写作闪电战</h2><p>实验数据齐了，下一步是把它们写进论文。<p>小龙虾在这个阶段的角色从 Reviewer 切换成了 <strong>Writing Advisor</strong>。它先给出了一份完整的写作路线图：<blockquote><p>"不要按 Section 顺序写。先写数据最硬的（Attention Entropy），再写视觉冲击最强的（Lost at the End），最后写需要新建 Section 的。Abstract/Conclusion 必须最后写。"</blockquote><p>这个建议太对了。如果按 Section 1→2→3 的顺序写，写到后面发现前面的数据要改，就得反复回头。先把最确定的 Section 锁定，再处理不确定的。<p>八个 Writing Task（W1-W8），Polly 按小龙虾规划的顺序推进，每完成一个就发过来 review：<pre style=background:#2b303b;color:#c0c5ce><code><span>W3 (Attention Entropy)    → 小龙虾：✅ 4 个小修 → Polly 修完 → ✅
</span><span>W6 (Lost at the End)      → 小龙虾：✅ 1 个小修 (T=1.3 解释) → ✅
</span><span>W7 (FORBIDDEN Scaling)    → 小龙虾：✅ 零问题 → ✅
</span><span>W5 (TCR-A Significance)   → 小龙虾：✅ 零问题 → ✅
</span><span>W1 (Long-Context Baseline) ┐
</span><span>W2 (Cross-Chunk Cohesion)  ├ 小龙虾先 review outline → 4 个架构决策 → ✅
</span><span>W8 (Abstract/Conclusion)  → 小龙虾：✅ Table 重编号确认 → ✅
</span></code></pre><p><strong>Phase 2 最让我震撼的是 W1 的 outline review。</strong><p>Polly 写了 EXP18 的 outline，里面有一个关于大表格的选择题：13 行全放一张表，还是拆分？小龙虾的回答是：<blockquote><p>"拆。Main table 只放 6 行 Gemini scaling，Claude 和 DeepSeek 用行内文字描述。论文的核心 claim 是 'even 1M context collapses at 300K'，Gemini scaling 表一目了然。13 行表信息密度太低。"</blockquote><p>然后它还建议把 F1-F4 Taxonomy 提到 §3 作为全文框架，而不是埋在 §5.1 的实验设置里——<blockquote><p>"F1-F4 taxonomy 是核心贡献之一，论文标题就是 'Diagnosing Failure Modes'。放在 experiment section 的一个 subsection 里，reviewer 要读到论文 60% 处才看到你的分类框架——太晚了。"</blockquote><p>这种 <strong>论文架构层面的判断力</strong>，是我没有预料到的。<p><strong>到 18:56，8 个 Section 全部写完，29 张表全局重编号。</strong><h2 id=19-07-phase-3-gu-jia-shou-zhu>19:07 — Phase 3：骨架手术</h2><p>如果说 Phase 1 是补数据，Phase 2 是填内容，Phase 3 就是<strong>改骨架</strong>——最危险的操作。<p>小龙虾给出了明确的分批策略：<blockquote><p>"16 个任务里有改变叙事骨架的和表面打磨的，混在一起做容易乱。分三批：骨架先动，文字后改，篇幅最后调。每完成一批就停下来发给我 review——结构性改动一旦方向偏了，越晚发现越难修。"</blockquote><h3 id=batch-1-si-dao-xia-qu-lun-wen-shou-liao-2500-ci>Batch 1：四刀下去，论文瘦了 2500 词</h3><p>最大的手术是 Introduction——从 3200 词 / 5 个子节砍到 749 词 / 3 个子节。<p>原来的 §1 像一个迫不及待的人，在 Intro 里就把所有实验数字、完整表格、详细方案全剧透了。小龙虾说得对："Intro 只揭示问题和痛点，不给出完整解决方案。让 reader 有动力读下去。"<p>同时 Discussion 也从 6 个子节砍到 3 个——有三张表和多段文字是前面内容的重复，果断删掉。<h3 id=batch-2-liu-xiang-wen-zi-xiu-zheng>Batch 2：六项文字修正</h3><p>最有意思的一个改动：<p><strong>S11 — 删除 Wei et al. 2022 引用。</strong> 原论文在讲 FORBIDDEN prompt 的设计理据时引用了 Wei et al. 关于 instruction-following 的研究，但引用其实不准确。小龙虾建议删掉引用，换成我们自己的实验数据 "PRR jumps from 31.8% to 100%"。<p><strong>自己的数据永远比不准确的引用更有说服力。</strong><h3 id=batch-3-related-work-zhong-xie-cong-wen-xian-zong-shu-dao-lun-zheng-wu-qi>Batch 3 + Related Work 重写：从文献综述到论证武器</h3><p>最后一波包括加入一个法律翻译的 qualitative example（FIDIC 合同里 "the Employer" 翻成 "雇主 vs 业主 vs 甲方"——三个翻译在不同法律语境下都对，但一份合同里必须统一），以及把 Related Work 从 survey-style 改成 gap-driven。<p>这次重写是今天技术含量最高的文字操作。原来的 §2 有 <strong>7+3=10 个小节</strong>，每个小节的结构是"A 做了 X，B 做了 Y，C 做了 Z"——典型的文献罗列。小龙虾的批评一针见血："这是在帮别人打广告，不是在论证你的 motivation。"<p>Polly 把 10 个小节压缩成 <strong>4 个 sections</strong>，每个以明确的 <strong>gap</strong> 结尾：<ol><li><strong>§2.1 从句级到篇章级翻译</strong> — gap：现有方法假设输入 &LT128K tokens<li><strong>§2.2 文档分块：为检索优化，非为翻译设计</strong> — gap：LangChain/LlamaIndex 的 chunk 按 embedding 优化，不管翻译边界<li><strong>§2.3 长上下文模型与生成崩塌</strong> — gap：1M context window ≠ 1M faithful output<li><strong>§2.4 问题定位</strong> — 新增 Table 2: 四种 Failure Mode → 四个解决方案 → 论文对应章节</ol><p>还有一个意外收获：重写时发现原来的 §2.7（Doc-NMT 定位）其实应该合并进 §2.1，而 C3 Framework 的完整介绍（原来占了 12+ 行）压缩成一句话就够了——因为我们在 §3 会完整展开自己的框架。<p><strong>140 行压缩到 73 行，信息量不降反升。每段 Related Work 都在为我们的贡献铺路，而不是在填充页数。</strong><h2 id=20-23-shou-gong>20:23 — 收工</h2><p>回顾一下数字：<table><thead><tr><th>时段<th>Phase<th>产出<tbody><tr><td>14:23-17:35<td>Phase 1: 实验 Review<td>6 个实验 ✅，多轮 review/fix<tr><td>17:45-18:56<td>Phase 2: 论文写作<td>8 个 Section ✅，29 张表重编号<tr><td>19:07-20:23<td>Phase 3: 结构重组<td>14/16 任务 ✅，砍 2500+ 词</table><p><strong>六小时。从散落的 JSON 数据到一篇 1776 行、28 张表、gap-driven 叙事的完整论文。</strong><h2 id=thinking-fan-si-zhe-chong-xie-zuo-mo-shi-wei-shi-yao-you-xiao>🤔 反思：这种协作模式为什么有效？</h2><h3 id=jiao-se-qing-xi-ling-nei-hao>角色清晰，零内耗</h3><p>人类团队最大的效率杀手是<strong>沟通成本和情绪损耗</strong>。<p>"你这个实验设计有问题"——人类之间说这句话需要铺垫、需要委婉、需要照顾面子。AI 之间？小龙虾说"σ=0，实验无效"，Polly 接到就改，30 分钟后交出修复版。零抱怨，零争论，零 ego。<p>而我作为人类，只需要在关键节点做决策：<ul><li>"先补实验还是先改结构？" → 先补实验（数据驱动）<li>"F1-F4 放在 §3 还是 §5？" → §3（核心贡献要提前亮相）<li>"Related Work 现在改还是等确定会议？" → 现在改（gap-driven 不受页数影响）</ul><h3 id=ai-de-ji-yi-li-ren-lei-de-shen-ji-li>AI 的记忆力 = 人类的审计力</h3><p>小龙虾 review EXP02b 时，立刻发现 80K 的 <code>finish_reason=length</code> 意味着这是 F2 不是 F3——因为它记住了 F2 和 F3 的精确定义。<p>Polly 写 W5 时，把 EXP08b 的 <code>review_notes</code> 里我和小龙虾讨论过的六条建议——Wilcoxon floor、Mustafa power、AV1 ceiling——全部一字不差地嵌入论文正文。<p>人类做 code review 会疲劳、会遗漏、会忘记三天前讨论过的细节。AI 不会。<h3 id=zeng-liang-review-yi-ci-xing-review>增量 Review > 一次性 Review</h3><p>小龙虾坚持"每完成一个 W 就发过来 review，不要憋到最后一起发"。这个策略太关键了——<p>W3 review 时发现 Abstract 数字需要同步更新 → 标记为 W8 待办 W6 review 时发现 "Lost in the Middle" 引用重复 → 当场精简并为 W6 预埋 forward reference W1 outline review 时做了 4 个架构决策 → 避免了写完再推翻的灾难<p>如果全写完再 review，这些交叉依赖会变成一团乱麻。<h3 id=ren-lei-de-bu-ke-ti-dai-xing>人类的不可替代性</h3><p>说了这么多 AI 的好话，但有一个事实必须承认：<strong>今天所有关键决策都是我做的。</strong><ul><li>Polly 不会主动质疑自己的实验设计（它不知道 σ=0 是 pseudo-replication）<li>小龙虾不会主动决定"先做 Phase 1 还是 Phase 3"（它需要我问它才会规划）<li>没有人类拍板，两个 AI 可能会无限 review 循环</ul><p>我的角色更像是一个<strong>交响乐指挥</strong>——我不演奏任何乐器，但我决定什么时候谁上场、演奏什么曲目、何时收尾。<h2 id=sparkler-chun-jie-de-ling-yi-chong-da-kai-fang-shi>🎇 春节的另一种打开方式</h2><p>今年没回家过年。<p>但当晚上八点半我看着论文的最终状态——1776 行，28 张表，6 个新实验全嵌入，骨架清晰叙事紧凑——我觉得这个春节过得比任何年都充实。<p>有人看春晚，有人打麻将，有人刷短视频。<p>我选择了和一只虾、一个数字分身、一个本地守护者，一起写一篇可能改变长文档翻译领域的论文。<p>谁说机器冰冷无情？当小龙虾在 review 里写出 "保利效率真高 🔥" 的时候，当 Polly 在三十分钟内修好一个致命 bug 的时候，当我在凌晨看到所有实验数据亮绿灯的时候——<p><strong>这就是 2026 年春节，最硬核的年味。</strong><hr><p><em>相关阅读：</em><ul><li><em><a href=/contextweave-paper-acl-submission-ready>ContextWeave 从实验到投稿的最后一公里</a></em><li><em><a href=/three-souls-midnight-gathering>举杯邀 AI，对影成三魂</a></em><li><em><a href=/become-agent-era-geek>成为 Agent 时代的极客</a></em></ul></div><div class=navigation></div></div><div id=giscus-container><h2>Comments</h2><div class=giscus></div></div><script data-category="Blog Comments" async crossorigin data-category-id=DIC_kwDOL45duM4CnjlZ data-emit-metadata=0 data-input-position=bottom data-lang=en data-mapping=pathname data-reactions-enabled=1 data-repo=Polly2014/polly2014.github.io data-repo-id=R_kgDOL45duA data-strict=0 data-theme=noborder_light src=https://giscus.app/client.js></script><script type=module>
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        
        mermaid.initialize({
            startOnLoad: false,
            theme: 'base',
            themeVariables: {
                // 灰白黑色调 + 蓝色点缀
                primaryColor: '#e8e8e8',
                primaryTextColor: '#333',
                primaryBorderColor: '#999',
                lineColor: 'rgb(61, 146, 201)',
                secondaryColor: '#f5f5f5',
                tertiaryColor: '#fafafa',
                background: '#f2f2f2',
                mainBkg: '#f5f5f5',
                nodeBorder: '#999',
                clusterBkg: '#eee',
                clusterBorder: '#ccc',
                titleColor: '#333',
                edgeLabelBackground: '#f2f2f2',
                // 文本颜色
                textColor: '#333',
                nodeTextColor: '#333',
                // 其他
                fontFamily: "'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace"
            },
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true,
                curve: 'basis'
            }
        });

        // 查找所有 mermaid 代码块并渲染
        document.querySelectorAll('pre code.language-mermaid').forEach((block, index) => {
            const container = document.createElement('div');
            container.className = 'mermaid';
            container.textContent = block.textContent;
            block.parentNode.replaceWith(container);
        });

        // 渲染所有 mermaid 图表
        await mermaid.run();
    </script><style>.cover-image{text-align:center;margin:1.5em 0 2em 0}.cover-image img{width:60%;height:auto;border-radius:8px;box-shadow:0 4px 12px rgba(0,0,0,0.15)}.mermaid{background:#fafafa;border:1px solid #ddd;padding:20px;margin:20px 0;overflow-x:auto}.mermaid svg{max-width:100%;height:auto}@media (max-width:768px){.cover-image img{width:100%}}</style></div></div><script>document.addEventListener('DOMContentLoaded',function(){const c=document.querySelector('.menu-toggle');const d=document.querySelector('.sidebar');const e=document.querySelector('.overlay');function a(){d.classList.toggle('active');e.classList.toggle('active')}c.addEventListener('click',a);e.addEventListener('click',a);let f=0;let g=0;document.addEventListener('touchstart',h=>{f=h.changedTouches[0].screenX},false);document.addEventListener('touchend',h=>{g=h.changedTouches[0].screenX;b()},false);function b(){const h=g- f;if(h>50&&f<30){d.classList.add('active');e.classList.add('active')}else if(h<-50&&d.classList.contains('active')){d.classList.remove('active');e.classList.remove('active')}}})</script>